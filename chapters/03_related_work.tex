\chapter{Related Work}\label{chapter:related-work}
Data parallelism has been leveraged to improve the performance of machine learning systems \cite{alexnet2012}.
Several common frameworks implement data parallelism such as PyTorch \footnote{\href{https://pytorch.org/}{https://pytorch.org/}} and TensorFlow\footnote{\href{https://tensorflow.org/}{https://tensorflow.org/}} through a high-level API.
There are already some works that analyze the effects of data parallelism \cite{DBLP:journals/corr/abs-2003-11316}

Talk about distributed training, model and data parallelism works.
Talk about Hivemind paper and papers that Hivemind bases itself upon.
Basically explain why this thesis is needed at all.

