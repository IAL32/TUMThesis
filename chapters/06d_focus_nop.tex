\section{Focus on effects of the number of peers and vCPUs per peer}

Institutions and companies may have more than two machines at their disposal to perform distributed training.
So far, we have explored the effects on Hivemind of specific settings such as TBS, BS LR, GAS and LU.
Adding more nodes to a distributed training setting can lead to bottlenecks, especially when using a client-server approach \cite{Atre_2021, 8886576}.
In this section, we answer the following research question: what are the effects of scaling up the number of machines when using Hivemind?

\begin{figure}[ht]
    \centering
    % temporary
    \foreach \gas in {1, 2}
        {
            \begin{subfigure}[t]{0.35 \textwidth}
                \caption{}
                \includegraphics[width=\textwidth]{./figures/06_barplot-runtime_gas-\gas_scale-nop.pdf}
            \end{subfigure}
        }
    \caption{Runtime decrease in percent for Hivemind runs with 2, 4, 8, 16 peers and 8, 4, 2, 1 vCPUs respectively relative to baseline runs. Higher is better. Runs are aggregated across LR and the standard error amongst runs is shown with black bars.}
    \label{fig:runtime-decrease_scale-nop}
\end{figure}

The frequency at which peers average their model state is directly proportional to the number of peers, the throughput per second of each peer and the TBS.
In turn, the throughput per second is affected by several factors such as the BS, computational power of the node and wait times for I/O operations.

It might be difficult to isolate the effects of introducing more nodes from scaling the target batch size.
Thus, we decided to fix the target batch size to 1250 for this set of experiments and alter TBS, BS, LR, GAS and LU.

\begin{figure}[ht]
    \centering
    \foreach \gas in {1}
        {
            \foreach \lu in {True, False}
                {
                    \begin{subfigure}[t]{0.45\linewidth}
                        \centering
                        \caption{}
                        \includegraphics[width=\textwidth]{./figures/06_barplot-loss_gas-\gas_lu-\lu_scale-nop.pdf}
                    \end{subfigure}
                }
        }
    \caption{GAS = 1, accuracy decrease in percent for Hivemind runs with 2, 4, 8, 16 peers and 8, 4, 2, 1 vCPUs respectively relative to baseline runs. Higher is worse.}
    \label{fig:loss-increase_scale-nop}
\end{figure}

\begin{figure}[ht]
    \centering
    \foreach \gas in {2}
        {
            \foreach \lu in {True, False}
                {
                    \begin{subfigure}[t]{0.45\linewidth}
                        \centering
                        \caption{}
                        \includegraphics[width=\textwidth]{./figures/06_barplot-loss_gas-\gas_lu-\lu_scale-nop.pdf}
                    \end{subfigure}
                }
        }
    \caption{GAS = 2, accuracy decrease in percent for Hivemind runs with 2, 4, 8, 16 peers and 8, 4, 2, 1 vCPUs respectively relative to baseline runs. Higher is worse.}
\end{figure}

As we might expect, \autoref{fig:runtime-decrease_scale-nop} shows that increasing the number of peers dramatically decreases runtime.
The highest jump in runtime performance is between using one single peer (Hivemind disabled) and using two peers (Hivemind enabled).
Introducing four peers also cuts down runtime by around 50\% compared to using two peers across all experiments.
However, this effect does not appear to be linear.
The benefits of including more peers only increase by 10-15\% for eight peers and 4-6\% for sixteen peers.
If we take into consideration the decreased accuracy performance, there seems to be a sweet spot in terms of reducing the total runtime and an acceptable reduction in accuracy performance.
Using four peers seems to be the optimal number of peers when training with Hivemind on our configuration to obtain the maximum reduction of runtime without having a significant hit in terms of accuracy.
It remains an open question whether training these runs for longer would yield the same accuracy as the baseline runs but in less time overall.
Further experimentation may also show that increasing the TBS, and thus reducing the averaging frequency amongst peers, can be beneficial in runs where TBS is quickly reached.

\autoref{fig:loss-increase_scale-nop} shows that GAS and LU settings seem to generally have a similar effect compared to Hivemind runs with 2 peers and 8vCPUs presented in \autoref{sec:focus-effect-bs-lr-tbs}.
The graph also shows us a decrease in performance as we increase the number of peers, especially for experiments that have reached a higher accuracy.
In general, we noticed that compared to baseline experiments with bad performance, the accuracy does not change too much when using Hivemind.

\autoref{fig:times-stacked_scale-nop} shows the average time taken for each step in every different combination for the experiments changing NoP.
The increase in time taken for each operation is consistent with what we would expect: halving the number of computational power results in double the time taken per operation.
This is connected with the reduction in runtime increase benefits shown before.
As we half the computational power per peer, slower operations such as data loading, forward and backward pass stack up, eventually leading to slower runtimes.
It remains an open question however to see if increasing the number of peers and increasing the available computational power will solve these issues and by how much.

The network bandwidth utilization for different peer configurations is shown in \autoref{fig:net-recv-sys-bandwidth-mbs_scale-nop} and \autoref{fig:net-sent-sys-bandwidth-mbs_scale-nop}, and yield interesting results.
As we increase the number of peers in a training session, peers communicate more often, which can also be seen as these "bulbs" in the violin plots.
This is unsurprising, for two reasons:
first, the time to reach the fixed TBS of 1250 gets shorter as we add more peers, thus, the frequency at which peers communicate increases with the number of peers;
second, with more peers to average with, there is more data to exchange in terms of pings, synchronization messages and such.
We can see that with sixteen peers, the sent bandwidth utilization is almost exclusively around 5MB/s.
Nevertheless, even with sixteen peers, we did not see any significant CPU bottleneck caused by high network communication.

Finally, we make different observations for GAS and LU values as we presented in \autoref{sec:focus-local-updates} and \autoref{sec:focus-gradient-acc}.
Enabling LU for a higher number of peers seems to be very penalizing, especially with NoP=16.
Disabling LU instead yields more consistent accuracies in every experiment but seems to perform best for large values of LR.
Increasing GAS appears to worsen the situation when paired with LU=True, except for very low values of LR.
On the other hand, increasing GAS to 2 while disabling local updates seems to be a bit better, but not as consistently as decreasing TBS in \autoref{sec:focus-effect-bs-lr-tbs}.

Summarizing the findings, we can say the following for our setup:
\begin{itemize}
    \item Increasing the number of peers while maintaining the same computational power can reduce the total runtime by at least 30\%.
    \item However runtime reduction is not linear compared to the number of peers.
          The effects of reducing the data load times by using faster storage are still an open question.
    \item With local updates enabled, increasing the number of peers seems to have a worse effect on training accuracy.
          The effects of other values of TBS for a different number of peers is still an open question.
    \item Introducing more peers leads to more bandwidth usage as each peer exchanges more data with other averaging partners.
          This effect can become much larger for larger models and a much larger number of nodes.
\end{itemize}%

\begin{figure}[H]
    \centering
    \foreach \gas in {1, 2}
        {
            \begin{subfigure}[t]{0.34\textwidth}
                \centering
                \caption{}
                \includegraphics[width=\textwidth]{./figures/06_barplot-times_gas-\gas_scale-nop.pdf}
            \end{subfigure}%
        }
    \caption{
        Average times of data load (red), forward pass (green), backward pass (orange) and optimization step (blue) for Hivemind runs with 2, 4, 8, 16 peers and 8, 4, 2, 1 vCPUs respectively in seconds.
        Runs are further aggregated across LR.
    }
    \label{fig:times-stacked_scale-nop}
\end{figure}%


\begin{figure}[H]
    \centering
    \foreach \gas in {1, 2}
        {
            \begin{subfigure}[t]{0.30\linewidth}
                \centering
                \caption{}
                \includegraphics[width=\textwidth]{./figures/06_net-recv-sys-bandwidth-mbs_gas-\gas_scale-nop.pdf}
            \end{subfigure}%
        }
    \caption{Network received for Hivemind runs with 2, 4, 8, 16 peers and 8, 4, 2, 1 vCPUs respectively. Values $\geq 20$ MB/s are hidden and runs are aggregated across LR.}
    \label{fig:net-recv-sys-bandwidth-mbs_scale-nop}
\end{figure}%
\begin{figure}[H]
    \centering
    \foreach \gas in {1, 2}
        {
            \begin{subfigure}[t]{0.30\linewidth}
                \centering
                \caption{}
                \includegraphics[width=\textwidth]{./figures/06_net-sent-sys-bandwidth-mbs_gas-\gas_scale-nop.pdf}
            \end{subfigure}%
        }
    \caption{Network sent for Hivemind runs with 2, 4, 8, 16 peers and 8, 4, 2, 1 vCPUs respectively. Values $\geq 20$ MB/s are hidden and runs are aggregated across LR.}
    \label{fig:net-sent-sys-bandwidth-mbs_scale-nop}
\end{figure}
