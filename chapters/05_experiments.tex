\chapter{Experiments}\label{chapter:experiments}

Having access to more powerful hardware is a challenge for several reasons that may be outside of our control.
In the past years, there was a worldwide shortage of microchips that negatively impacted the ability to purchase state-of-the-art hardware such as CPUs and GPUs.
Thus, we would like to understand the effects of running distributed frameworks such as Hivemind on less powerful, older hardware.

To provide a fair comparison between experiments not running Hivemind and experiments that do, our experiments always have the same amount of vCPUs.
Finally, every experiment processes the same number of samples across all the participating peers, and the sum of processed samples may never be greater than 320,000.

An exception to this rule is made for experiments with an odd number of samples per peer.
For example, a run with batch size $128$ and 8 peers should result in 312.5 samples per peer, which is not possible.
In these cases, the number of samples per peer is rounded up to the nearest digit to form an even number.
This chapter describes the basic setup of our experiments.

\section{Base Case}

To preserve a comparison consistency between each experiment run, the number of steps depends on two factors: the number of peers involved in the training, and the batch size.
We designed our baseline experiments in a grid search, covering the following training hyperparameters:
\begin{itemize}
    \item Batch Size (BS): 32, 64 and 128;
    \item Learning Rate (LR): 0.001, 0.01 and 0.1;
    \item Max Steps (MS): 10.000 for BS=32, 5000 for BS=64, 2500 for BS=128.
    \item Gradient Accumulation Steps (GAS): 1 (no accumulation), 2 (with accumulation up to two steps)
\end{itemize}

\begin{tabularx}{\linewidth}{ |p{3cm}|p{3cm}|p{3cm}|p{3cm}|  }
    \caption{
        List of baseline experiments and hyperparameters
    }\label{table:baseline-experiments}                       \\
    \hline
    \multicolumn{4}{|c|}{Baseline experiments}                \\
    \hline
    Max Steps & Batch Size & Learning Rate & Grad. Acc. Steps \\
    \hline
    10.000    & 32         & 0.001         & 1                \\
    10.000    & 32         & 0.01          & 1                \\
    10.000    & 32         & 0.1           & 1                \\
    5000      & 64         & 0.001         & 1                \\
    5000      & 64         & 0.01          & 1                \\
    5000      & 64         & 0.1           & 1                \\
    2500      & 128        & 0.001         & 1                \\
    2500      & 128        & 0.01          & 1                \\
    2500      & 128        & 0.1           & 1                \\
    \hline
    10.000    & 32         & 0.001         & 2                \\
    10.000    & 32         & 0.01          & 2                \\
    10.000    & 32         & 0.1           & 2                \\
    5000      & 64         & 0.001         & 2                \\
    5000      & 64         & 0.01          & 2                \\
    5000      & 64         & 0.1           & 2                \\
    2500      & 128        & 0.001         & 2                \\
    2500      & 128        & 0.01          & 2                \\
    2500      & 128        & 0.1           & 2                \\
    \hline
\end{tabularx}

The machines used for baseline runs have 16vCPUs and each experiment is repeated 4 times to observe the reproducibility of the measurements.
Hivemind features such as the DHT and the Optimizer wrapper are completely deactivated for these runs.
\autoref{table:baseline-experiments} lists all the 18 combinations of experiments that we cover in this thesis.

\section{Not-Baseline Case}

To test and isolate the effects of using Hivemind for distributed training, each of our experiments changes only a single parameter at a time.
For this, we can divide the set of non-baseline cases into different categories depending on which parameter has been changed.
In every non-base case scenario described in this section, at least two nodes are involved in the training of the underlying NN model.

The model and the dataset remain the same across each run, and every peer has full access to the entire dataset through our CEPH cluster.
We repeat the same experiments as the baseline runs, and further explore the following Hivemind settings and questions:
\begin{itemize}
    \item \textbf{Number of Peers (NoP)}: 2, 4, 8 and 16; for loads like the experiment that we are running, is communication between many nodes a bottleneck?
    \item \textbf{Number of logical cores per node (vCPUs)}: 1, 2, 4, 8 and 16; using the same amount of computational power across many nodes, do we get to a target loss faster?
    \item \textbf{Target Batch Size (TBS)}: 10.000, 5000, 2500, 1250 and 625; using smaller target batch size, do we get faster to the target loss?
    \item \textbf{Max Steps (MS)}: 5000, 2500, 1250 and 625; this parameter depends on the number of peers and batch size, but the total is always 10.000 steps per experiment;
    \item \textbf{Use Local Updates (LU)}: \texttt{True} or \texttt{False}; Hivemind allows us to control when to schedule gradient, model and parameter averaging. How does this setting affect training?
\end{itemize}

The \autoref{table:hivemind-experiments} shows a list of the combination of experiments that we performed to test Hivemind.
In total, we have executed 288 experiments for this thesis.

\begin{tabularx}{\linewidth}{ |c|c|c|c|c|c|c|c|  }
    \caption{
        List of Hivemind experiments and hyperparameters.
        Every experiment has been executed once, and every time with at least two peers.
    }\label{table:hivemind-experiments}                                                      \\
    \hline
    \multicolumn{8}{|c|}{Experiments testing for the effect of target batch size (TBS)}      \\
    \hline
    MS   & NoP & vCPUs & BS  & LR               & TBS                           & GAS & LU   \\
    \hline
    5000 & 2   & 8     & 32  & 0.001, 0.01, 0.1 & 10.000, 5000, 2500, 1250, 625 & 1,2 & T, F \\
    2500 & 2   & 8     & 64  & 0.001, 0.01, 0.1 & 10.000, 5000, 2500, 1250, 625 & 1,2 & T, F \\
    1250 & 2   & 8     & 128 & 0.001, 0.01, 0.1 & 10.000, 5000, 2500, 1250, 625 & 1,2 & T, F \\
    \hline
    \multicolumn{8}{|c|}{Experiments testing for the effect of the number of peers (NoP)}    \\
    \hline
    MS   & NoP & vCPUs & BS  & LR               & TBS                           & GAS & LU   \\
    \hline
    2500 & 4   & 4     & 32  & 0.001, 0.01, 0.1 & 1250                          & 1,2 & T, F \\
    1250 & 8   & 2     & 32  & 0.001, 0.01, 0.1 & 1250                          & 1,2 & T, F \\
    625  & 16  & 1     & 32  & 0.001, 0.01, 0.1 & 1250                          & 1,2 & T, F \\
    1250 & 4   & 4     & 64  & 0.001, 0.01, 0.1 & 1250                          & 1,2 & T, F \\
    625  & 8   & 2     & 64  & 0.001, 0.01, 0.1 & 1250                          & 1,2 & T, F \\
    313  & 16  & 1     & 64  & 0.001, 0.01, 0.1 & 1250                          & 1,2 & T, F \\
    625  & 4   & 4     & 128 & 0.001, 0.01, 0.1 & 1250                          & 1,2 & T, F \\
    313  & 8   & 2     & 128 & 0.001, 0.01, 0.1 & 1250                          & 1,2 & T, F \\
    157  & 16  & 1     & 128 & 0.001, 0.01, 0.1 & 1250                          & 1,2 & T, F \\
    \hline
\end{tabularx}
