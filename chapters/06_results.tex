\chapter{RESULTS}\label{chapter:results}

In this thesis, we are not looking to obtain the best possible combination of hyperparameters for training loss or model accuracy.
Instead, we want to observe the effects on training with Hivemind when tuning common hyperparameters such as batch size and learning rate and Hivemind hyperparameters such as the TBS.
In this thesis, we analyze the performance and limits of training using Hivemind rather than looking for the best model.

\section{BASELINE RUNS}

We begin this chapter by showing the results that we have obtained with the baseline runs.
As mentioned previously in \autoref{chapter:setup}, all baseline experiments are executed on machines with the same configuration, and the total number of samples processed is always the same.
\autoref{fig:baseline-runtimes} shows the average runtimes for baseline runs in minutes.
As we might have expected, most runs take more or less the same amount of time, as the total number of samples processed is the same for every run
\footnote{
    BS=128 takes more time due to resource contention happening during the execution of the baseline runs.
}.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.6\textwidth]{./figures/06_barplot-runtime_baseline-16vCPUs-GAS-1.pdf}
    \caption{
        Average runtimes (bars) of baseline experiments in minutes.
        Runs are aggregated across LR, with the standard deviation amongst reruns as the black bars.
        The black dashed line indicates the throughput in samples per second.
    }
    \label{fig:baseline-runtimes}
\end{figure}

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.6\textwidth]{./figures/06_barplot-losses_baseline-16vCPUs-GAS-1.pdf}
    \caption{Maximum accuracy achieved by baseline runs, averaged across re-runs.}
    \label{fig:baseline-losses}
\end{figure}

Baseline runs do not use distributed algorithms and all Hivemind features are switched off.
However, \autoref{fig:net-recv_baseline} shows that there is some network activity.
On average, every machine receives a constant 1.5 MB/s of data on its network.
This may be due to several factors, such as KVM management data, OpenNebula pings, and CEPH data being read.

In the Setup section, we also introduced our monitoring tool of choice \textit{wandb}.
Because this is an online monitoring tool, some data about our runs is periodically sent to the Weights and Biases server for storage and visualizations.

In \autoref{fig:net-sent_baseline}, which shows the bandwidth used for send operations across all baseline runs, we can observe the bandwidth in MB/s used for each run.
On average, this is roughly 0.02 MB/s on every run, a value that can be mostly attributed to \textit{wandb} and other background monitoring operations such as OpenNebula.

In future sections, we will always account for these effects when performing comparisons with baseline runs.

\begin{figure}[ht]
    \centering
    \begin{subfigure}[t]{0.475 \textwidth}
        \centering
        \caption{Network bandwidth sent in MB/s for baseline runs. Values above 0.07 are hidden. Runs are aggregated across LR.}
        \label{fig:net-sent_baseline}
        \includegraphics[width=0.5\textwidth]{./figures/06_net-recv_baseline-16vCPUs-GAS-1.pdf}
    \end{subfigure}
    \centering
    \begin{subfigure}[t]{0.475 \textwidth}
        \centering
        \caption{Network bandwidth received in MB/s for baseline runs. Values above 5 are hidden. Runs are aggregated across LR.}
        \label{fig:net-recv_baseline}
        \includegraphics[width=0.5\textwidth]{./figures/06_net-sent_baseline-16vCPUs-GAS-1.pdf}
    \end{subfigure}%
    \hfill
    \caption{Network bandwidth sent and received in MB/s for baseline runs. Runs are aggregated across LR.}
\end{figure}

\autoref{fig:baseline-times-stacked} shows the average times for data load, forward pass, backward pass and optimization step across batch sizes in baseline runs for both GAS=1 and GAS=2.
As we might expect, the time it takes for a single step to complete is linearly dependent on the batch size.
The learning rate (LR) does not affect the time it takes for each step to complete, so we aggregated the runs for each batch size.
By contrast, the number of gradient accumulation steps (GAS) seems to shave off some time for every batch size.
However, the total runtimes in \autoref{fig:baseline-runtimes} do not seem to reflect this improvement.
Because of this, throughout this chapter, we will keep showing GAS runs separately, as it still might affect some other aspects of training.

We further note that each step's average time remains relatively unchanged throughout every experiment, given the same computational power, except for the data load and optimizer steps
\footnote{We will not show anymore the times of every step besides the optimizer step, as they remain generally constant.}.
The irregularity of the storage medium that we used for the experiment, CEPH, is to blame for the slight irregularities in the data load step.
Regarding the optimizer step, its irregularities are due to two main factors: Hivemind settings and overcommitted nodes.

We will explore later in this chapter the effects of Hivemind settings on the optimizer step.
Overcommitted nodes are a consequence of the cloud environment where the machines that perform our experiments are set up.
Because we have limited resources in our cluster, sometimes other researchers may need to overcommit the same node vCPUs to perform their experiments.
This causes several issues when training in a distributed setting with Hivemind, such as nodes not responding for long periods of time, sometimes even minutes.
In such cases, two things can happen:

\begin{itemize}
    \item if the non-responding node or nodes were not participating in an averaging round, other participating nodes will wait for 10 seconds, and then start an averaging round without other nodes;
    \item if the node was actively participating in an averaging round, nodes will wait for the node to come back for 300 seconds or five minutes.
\end{itemize}

Future efforts to replicate the results presented in this thesis may wish to pin their resources to prevent or reduce these issues from happening.

In \autoref{fig:baseline-times-stacked} we can also notice the big impact that data loading has on every step.
Almost 1/2 of the total time for each step consists in waiting for the data to load.
As we increase the number of cores per peer, CPU utilization decreases, as the CPU is idle during I/O wait times and normal operations such as forward and backward pass take less time.
This is a bottleneck that can easily be tackled through several means, such as having a faster storage backend or if that is not available, faster data loader frameworks and algorithms \cite{isenko2022bottleneck, leclerc2022ffcv}.
Future work may make use of local, faster storage backed by SSD to achieve faster data load speeds, helping us rule out the effects of data loading on training with Hivemind.

\begin{minipage}{\linewidth}
    \begin{minipage}{0.45\linewidth}
        \begin{figure}[H]
            \centering
            \includegraphics[width=\textwidth]{./figures/06_barplot-times_baseline-16vCPUs-GAS-1.pdf}
            \caption{
                Average times of step data load (red), forward pass (green), backward pass (orange) and optimization step (blue) baseline experiments in seconds.
                Runs are further aggregated across LR and the standard error amongst runs is shown with black bars.
            }
            \label{fig:baseline-times-stacked}
        \end{figure}
    \end{minipage}
    \hspace{0.05\linewidth}
    \begin{minipage}{0.45\linewidth}
        \begin{figure}[H]
            \centering
            \includegraphics[width=\textwidth]{./figures/06_barplot-times-opt_baseline-16vCPUs-GAS-1.pdf}
            \caption{
                Cumulative time taken by the \texttt{opt.step()} for every batch size, in seconds.
                Runs are further aggregated across LR and the standard error amongst runs is shown with black bars.
            }
            \label{fig:baseline-times-opt}
        \end{figure}
    \end{minipage}
\end{minipage}

\autoref{fig:baseline-times-stacked} further shows the very small impact of the optimization step within each step, taking 0.015 seconds on average to complete, independently from the batch size.
In theory, we should expect that reducing the frequency at which the optimization step is called also reduces its contribution on overall training.
\autoref{fig:baseline-times-opt} shows the total amount of time spent for each run to perform \texttt{opt.step()}, grouped by LR.
Doubling the batch size indeed reduces this contribution, as the maximum number of steps is divided by two.
Because backpropagation scales with the number of outputs, performing the optimization step does not scale up with the increased input size.
As we might expect from \autoref{alg:grad-acc-training}, doubling GAS led to half the time spent on the optimizer step, as it is called exactly half of the time.
In the next sections, we will further analyze the effects on the optimization step when increasing GAS together with other Hivemind settings.

\input{chapters/06a_focus_batch_size.tex}

\input{chapters/06b_focus_gradient_acc.tex}

\input{chapters/06c_focus_local_updates.tex}

\input{chapters/06d_focus_nop.tex}
