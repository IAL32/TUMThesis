@book{latex,
  title     = {LaTeX : A Documentation Preparation System User's Guide and Reference Manual},
  publisher = {Addison-Wesley Professional},
  year      = {1994},
  author    = {Leslie Lamport}
}

@inproceedings{isenko2022bottleneck,
  author    = {Isenko, Alexander and Mayer, Ruben and Jedele, Jeffrey and Jacobsen, Hans-Arno},
  title     = {Where Is My Training Bottleneck? Hidden Trade-Offs in Deep Learning Preprocessing Pipelines},
  year      = {2022},
  isbn      = {9781450392495},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3514221.3517848},
  doi       = {10.1145/3514221.3517848},
  abstract  = {Preprocessing pipelines in deep learning aim to provide sufficient data throughput to keep the training processes busy. Maximizing resource utilization is becoming more challenging as the throughput of training processes increases with hardware innovations (e.g., faster GPUs, TPUs, and inter-connects) and advanced parallelization techniques that yield better scalability. At the same time, the amount of training data needed in order to train increasingly complex models is growing. As a consequence of this development, data preprocessing and provisioning are becoming a severe bottleneck in end-to-end deep learning pipelines.In this paper, we provide an in-depth analysis of data preprocessing pipelines from four different machine learning domains. We introduce a new perspective on efficiently preparing datasets for end-to-end deep learning pipelines and extract individual trade-offs to optimize throughput, preprocessing time, and storage consumption. Additionally, we provide an open-source profiling library that can automatically decide on a suitable preprocessing strategy to maximize throughput. By applying our generated insights to real-world use-cases, we obtain an increased throughput of 3x to 13x compared to an untuned system while keeping the pipeline functionally identical. These findings show the enormous potential of data pipeline tuning.},
  booktitle = {Proceedings of the 2022 International Conference on Management of Data},
  pages     = {1825–1839},
  numpages  = {15},
  keywords  = {data processing, datasets, preprocessing, machine learning, deep learning},
  location  = {Philadelphia, PA, USA},
  series    = {SIGMOD '22}
}

@article{ramesh2021zero,
  author     = {Aditya Ramesh and
                Mikhail Pavlov and
                Gabriel Goh and
                Scott Gray and
                Chelsea Voss and
                Alec Radford and
                Mark Chen and
                Ilya Sutskever},
  title      = {Zero-Shot Text-to-Image Generation},
  journal    = {CoRR},
  volume     = {abs/2102.12092},
  year       = {2021},
  url        = {https://arxiv.org/abs/2102.12092},
  eprinttype = {arXiv},
  eprint     = {2102.12092},
  timestamp  = {Tue, 02 Mar 2021 12:11:01 +0100},
  biburl     = {https://dblp.org/rec/journals/corr/abs-2102-12092.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@article{ryabinin2020learning,
  author     = {Maksim Riabinin and
                Anton Gusev},
  title      = {Learning@home: Crowdsourced Training of Large Neural Networks using
                Decentralized Mixture-of-Experts},
  journal    = {CoRR},
  volume     = {abs/2002.04013},
  year       = {2020},
  url        = {https://arxiv.org/abs/2002.04013},
  eprinttype = {arXiv},
  eprint     = {2002.04013},
  timestamp  = {Wed, 12 Feb 2020 16:38:55 +0100}
}

@article{ryabinin2021mosphit,
  author     = {Max Ryabinin and
                Eduard Gorbunov and
                Vsevolod Plokhotnyuk and
                Gennady Pekhimenko},
  title      = {Moshpit {SGD:} Communication-Efficient Decentralized Training on Heterogeneous
                Unreliable Devices},
  journal    = {CoRR},
  volume     = {abs/2103.03239},
  year       = {2021},
  url        = {https://arxiv.org/abs/2103.03239},
  eprinttype = {arXiv},
  eprint     = {2103.03239},
  timestamp  = {Mon, 15 Mar 2021 17:30:55 +0100},
  biburl     = {https://dblp.org/rec/journals/corr/abs-2103-03239.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@article{shazeer2017outrageously,
  author     = {Noam Shazeer and
                Azalia Mirhoseini and
                Krzysztof Maziarz and
                Andy Davis and
                Quoc V. Le and
                Geoffrey E. Hinton and
                Jeff Dean},
  title      = {Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts
                Layer},
  journal    = {CoRR},
  volume     = {abs/1701.06538},
  year       = {2017},
  url        = {http://arxiv.org/abs/1701.06538},
  eprinttype = {arXiv},
  eprint     = {1701.06538},
  timestamp  = {Mon, 13 Aug 2018 16:46:11 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/ShazeerMMDLHD17.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@misc{hivemind,
  author       = {Learning{@}home team},
  title        = {{H}ivemind: a {L}ibrary for {D}ecentralized {D}eep {L}earning},
  year         = {2020},
  howpublished = {\url{https://github.com/learning-at-home/hivemind}}
}

@misc{learning30:online,
  author       = {Max Ryabinin and Anton Gusev},
  title        = {learning@home},
  howpublished = {\url{https://learning-at-home.github.io/}},
  month        = {},
  year         = {}
}

@article{xin2021production,
  author     = {Doris Xin and
                Hui Miao and
                Aditya G. Parameswaran and
                Neoklis Polyzotis},
  title      = {Production Machine Learning Pipelines: Empirical Analysis and Optimization
                Opportunities},
  journal    = {CoRR},
  volume     = {abs/2103.16007},
  year       = {2021},
  url        = {https://arxiv.org/abs/2103.16007},
  eprinttype = {arXiv},
  eprint     = {2103.16007},
  timestamp  = {Wed, 07 Apr 2021 15:31:46 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/abs-2103-16007.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@article{devlin2018bert,
  author     = {Jacob Devlin and
                Ming{-}Wei Chang and
                Kenton Lee and
                Kristina Toutanova},
  title      = {{BERT:} Pre-training of Deep Bidirectional Transformers for Language
                Understanding},
  journal    = {CoRR},
  volume     = {abs/1810.04805},
  year       = {2018},
  url        = {http://arxiv.org/abs/1810.04805},
  eprinttype = {arXiv},
  eprint     = {1810.04805},
  timestamp  = {Tue, 30 Oct 2018 20:39:56 +0100},
  biburl     = {https://dblp.org/rec/journals/corr/abs-1810-04805.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@article{brown2020gpt3,
  author     = {Tom B. Brown and
                Benjamin Mann and
                Nick Ryder and
                Melanie Subbiah and
                Jared Kaplan and
                Prafulla Dhariwal and
                Arvind Neelakantan and
                Pranav Shyam and
                Girish Sastry and
                Amanda Askell and
                Sandhini Agarwal and
                Ariel Herbert{-}Voss and
                Gretchen Krueger and
                Tom Henighan and
                Rewon Child and
                Aditya Ramesh and
                Daniel M. Ziegler and
                Jeffrey Wu and
                Clemens Winter and
                Christopher Hesse and
                Mark Chen and
                Eric Sigler and
                Mateusz Litwin and
                Scott Gray and
                Benjamin Chess and
                Jack Clark and
                Christopher Berner and
                Sam McCandlish and
                Alec Radford and
                Ilya Sutskever and
                Dario Amodei},
  title      = {Language Models are Few-Shot Learners},
  journal    = {CoRR},
  volume     = {abs/2005.14165},
  year       = {2020},
  url        = {https://arxiv.org/abs/2005.14165},
  eprinttype = {arXiv},
  eprint     = {2005.14165},
  timestamp  = {Wed, 03 Jun 2020 11:36:54 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/abs-2005-14165.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@article{peters2018elmo,
  author     = {Matthew E. Peters and
                Mark Neumann and
                Mohit Iyyer and
                Matt Gardner and
                Christopher Clark and
                Kenton Lee and
                Luke Zettlemoyer},
  title      = {Deep contextualized word representations},
  journal    = {CoRR},
  volume     = {abs/1802.05365},
  year       = {2018},
  url        = {http://arxiv.org/abs/1802.05365},
  eprinttype = {arXiv},
  eprint     = {1802.05365},
  timestamp  = {Mon, 13 Aug 2018 16:48:54 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/abs-1802-05365.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@article{radford2019language,
  title  = {Language Models are Unsupervised Multitask Learners},
  author = {Radford, Alec and Wu, Jeff and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
  year   = {2019}
}

@article{shoeybi2019megatronlm,
  author     = {Mohammad Shoeybi and
                Mostofa Patwary and
                Raul Puri and
                Patrick LeGresley and
                Jared Casper and
                Bryan Catanzaro},
  title      = {Megatron-LM: Training Multi-Billion Parameter Language Models Using
                Model Parallelism},
  journal    = {CoRR},
  volume     = {abs/1909.08053},
  year       = {2019},
  url        = {http://arxiv.org/abs/1909.08053},
  eprinttype = {arXiv},
  eprint     = {1909.08053},
  timestamp  = {Tue, 24 Sep 2019 11:33:51 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/abs-1909-08053.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@misc{microsoft2020turingnlg,
  author       = {Microsoft},
  title        = {Turing-NLG: A 17-billion-parameter language model by Microsoft - Microsoft Research},
  howpublished = {\url{https://www.microsoft.com/en-us/research/blog/turing-nlg-a-17-billion-parameter-language-model-by-microsoft/}},
  month        = {05},
  year         = {2020}
}

@article{raffael2019t5,
  author     = {Colin Raffel and
                Noam Shazeer and
                Adam Roberts and
                Katherine Lee and
                Sharan Narang and
                Michael Matena and
                Yanqi Zhou and
                Wei Li and
                Peter J. Liu},
  title      = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text
                Transformer},
  journal    = {CoRR},
  volume     = {abs/1910.10683},
  year       = {2019},
  url        = {http://arxiv.org/abs/1910.10683},
  eprinttype = {arXiv},
  eprint     = {1910.10683},
  timestamp  = {Fri, 05 Feb 2021 15:43:41 +0100},
  biburl     = {https://dblp.org/rec/journals/corr/abs-1910-10683.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@article{smith2022megatronturingnlg,
  author     = {Shaden Smith and
                Mostofa Patwary and
                Brandon Norick and
                Patrick LeGresley and
                Samyam Rajbhandari and
                Jared Casper and
                Zhun Liu and
                Shrimai Prabhumoye and
                George Zerveas and
                Vijay Korthikanti and
                Elton Zheng and
                Rewon Child and
                Reza Yazdani Aminabadi and
                Julie Bernauer and
                Xia Song and
                Mohammad Shoeybi and
                Yuxiong He and
                Michael Houston and
                Saurabh Tiwary and
                Bryan Catanzaro},
  title      = {Using DeepSpeed and Megatron to Train Megatron-Turing {NLG} 530B,
                {A} Large-Scale Generative Language Model},
  journal    = {CoRR},
  volume     = {abs/2201.11990},
  year       = {2022},
  url        = {https://arxiv.org/abs/2201.11990},
  eprinttype = {arXiv},
  eprint     = {2201.11990},
  timestamp  = {Wed, 02 Feb 2022 15:00:01 +0100},
  biburl     = {https://dblp.org/rec/journals/corr/abs-2201-11990.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{alexnet2012,
  author    = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  booktitle = {Advances in Neural Information Processing Systems},
  editor    = {F. Pereira and C. J. C. Burges and L. Bottou and K. Q. Weinberger},
  pages     = {},
  publisher = {Curran Associates, Inc.},
  title     = {ImageNet Classification with Deep Convolutional Neural Networks},
  url       = {https://proceedings.neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf},
  volume    = {25},
  year      = {2012}
}

@inbook{Rumelhart1986learning,
  author    = {Rumelhart, D. E. and Hinton, G. E. and Williams, R. J.},
  title     = {Learning Internal Representations by Error Propagation},
  year      = {1986},
  isbn      = {026268053X},
  publisher = {MIT Press},
  address   = {Cambridge, MA, USA},
  booktitle = {Parallel Distributed Processing: Explorations in the Microstructure of Cognition, Vol. 1: Foundations},
  pages     = {318–362},
  numpages  = {45}
}

@article{karras2019stylegan2,
  author     = {Tero Karras and
                Samuli Laine and
                Miika Aittala and
                Janne Hellsten and
                Jaakko Lehtinen and
                Timo Aila},
  title      = {Analyzing and Improving the Image Quality of StyleGAN},
  journal    = {CoRR},
  volume     = {abs/1912.04958},
  year       = {2019},
  url        = {http://arxiv.org/abs/1912.04958},
  eprinttype = {arXiv},
  eprint     = {1912.04958},
  timestamp  = {Thu, 02 Jan 2020 18:08:18 +0100},
  biburl     = {https://dblp.org/rec/journals/corr/abs-1912-04958.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@article{li2019federatedlearning,
  author     = {Qinbin Li and
                Zeyi Wen and
                Zhaomin Wu and
                Sixu Hu and
                Naibo Wang and
                Xu Liu and
                Bingsheng He},
  title      = {A Survey on Federated Learning Systems: Vision, Hype and Reality for
                Data Privacy and Protection},
  journal    = {CoRR},
  volume     = {abs/1907.09693},
  year       = {2019},
  url        = {http://arxiv.org/abs/1907.09693},
  eprinttype = {arXiv},
  eprint     = {1907.09693},
  timestamp  = {Tue, 02 Nov 2021 07:45:37 +0100},
  biburl     = {https://dblp.org/rec/journals/corr/abs-1907-09693.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@article{huang2018gpipe,
  author     = {Yanping Huang and
                Yonglong Cheng and
                Dehao Chen and
                HyoukJoong Lee and
                Jiquan Ngiam and
                Quoc V. Le and
                Zhifeng Chen},
  title      = {GPipe: Efficient Training of Giant Neural Networks using Pipeline
                Parallelism},
  journal    = {CoRR},
  volume     = {abs/1811.06965},
  year       = {2018},
  url        = {http://arxiv.org/abs/1811.06965},
  eprinttype = {arXiv},
  eprint     = {1811.06965},
  timestamp  = {Sun, 25 Nov 2018 18:57:12 +0100},
  biburl     = {https://dblp.org/rec/journals/corr/abs-1811-06965.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{dean2012distbelief,
  title     = {Large Scale Distributed Deep Networks},
  author    = {Jeffrey Dean and Greg S. Corrado and Rajat Monga and Kai Chen and Matthieu Devin and Quoc V. Le and Mark Z. Mao and Marc’Aurelio Ranzato and Andrew Senior and Paul Tucker and Ke Yang and Andrew Y. Ng},
  year      = {2012},
  booktitle = {NIPS}
}

@article{Jacobs1991mixtureofexperts,
  author  = {Jacobs, Robert A. and Jordan, Michael I. and Nowlan, Steven J. and Hinton, Geoffrey E.},
  journal = {Neural Computation},
  title   = {Adaptive Mixtures of Local Experts},
  year    = {1991},
  volume  = {3},
  number  = {1},
  pages   = {79-87},
  doi     = {10.1162/neco.1991.3.1.79}
}

@article{riabinin2020hivemind,
  author     = {Maksim Riabinin and
                Anton Gusev},
  title      = {Learning@home: Crowdsourced Training of Large Neural Networks using
                Decentralized Mixture-of-Experts},
  journal    = {CoRR},
  volume     = {abs/2002.04013},
  year       = {2020},
  url        = {https://arxiv.org/abs/2002.04013},
  eprinttype = {arXiv},
  eprint     = {2002.04013},
  timestamp  = {Wed, 12 Feb 2020 16:38:55 +0100},
  biburl     = {https://dblp.org/rec/journals/corr/abs-2002-04013.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@article{Krizhevsky2014owt,
  author     = {Alex Krizhevsky},
  title      = {One weird trick for parallelizing convolutional neural networks},
  journal    = {CoRR},
  volume     = {abs/1404.5997},
  year       = {2014},
  url        = {http://arxiv.org/abs/1404.5997},
  eprinttype = {arXiv},
  eprint     = {1404.5997},
  timestamp  = {Mon, 13 Aug 2018 16:48:41 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/Krizhevsky14.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@article{goyal2017accurate,
  author     = {Priya Goyal and
                Piotr Doll{\'{a}}r and
                Ross B. Girshick and
                Pieter Noordhuis and
                Lukasz Wesolowski and
                Aapo Kyrola and
                Andrew Tulloch and
                Yangqing Jia and
                Kaiming He},
  title      = {Accurate, Large Minibatch {SGD:} Training ImageNet in 1 Hour},
  journal    = {CoRR},
  volume     = {abs/1706.02677},
  year       = {2017},
  url        = {http://arxiv.org/abs/1706.02677},
  eprinttype = {arXiv},
  eprint     = {1706.02677},
  timestamp  = {Mon, 13 Aug 2018 16:49:10 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/GoyalDGNWKTJH17.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@article{you2017scaling,
  author     = {Yang You and
                Igor Gitman and
                Boris Ginsburg},
  title      = {Scaling {SGD} Batch Size to 32K for ImageNet Training},
  journal    = {CoRR},
  volume     = {abs/1708.03888},
  year       = {2017},
  url        = {http://arxiv.org/abs/1708.03888},
  eprinttype = {arXiv},
  eprint     = {1708.03888},
  timestamp  = {Mon, 13 Aug 2018 16:49:16 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/abs-1708-03888.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{deng2009imagenet,
  author    = {Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Kai Li and Li Fei-Fei},
  booktitle = {2009 IEEE Conference on Computer Vision and Pattern Recognition},
  title     = {ImageNet: A large-scale hierarchical image database},
  year      = {2009},
  volume    = {},
  number    = {},
  pages     = {248-255},
  doi       = {10.1109/CVPR.2009.5206848}
}

@article{he2015deep,
  author     = {Kaiming He and
                Xiangyu Zhang and
                Shaoqing Ren and
                Jian Sun},
  title      = {Deep Residual Learning for Image Recognition},
  journal    = {CoRR},
  volume     = {abs/1512.03385},
  year       = {2015},
  url        = {http://arxiv.org/abs/1512.03385},
  eprinttype = {arXiv},
  eprint     = {1512.03385},
  timestamp  = {Wed, 17 Apr 2019 17:23:45 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/HeZRS15.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/KeskarMNST16,
  author     = {Nitish Shirish Keskar and
                Dheevatsa Mudigere and
                Jorge Nocedal and
                Mikhail Smelyanskiy and
                Ping Tak Peter Tang},
  title      = {On Large-Batch Training for Deep Learning: Generalization Gap and
                Sharp Minima},
  journal    = {CoRR},
  volume     = {abs/1609.04836},
  year       = {2016},
  url        = {http://arxiv.org/abs/1609.04836},
  eprinttype = {arXiv},
  eprint     = {1609.04836},
  timestamp  = {Mon, 13 Aug 2018 16:46:48 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/KeskarMNST16.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-2003-11316,
  author     = {Namhoon Lee and
                Philip H. S. Torr and
                Martin Jaggi},
  title      = {Data Parallelism in Training Sparse Neural Networks},
  journal    = {CoRR},
  volume     = {abs/2003.11316},
  year       = {2020},
  url        = {https://arxiv.org/abs/2003.11316},
  eprinttype = {arXiv},
  eprint     = {2003.11316},
  timestamp  = {Wed, 01 Apr 2020 17:39:11 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/abs-2003-11316.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-1904-00962,
  author     = {Yang You and
                Jing Li and
                Jonathan Hseu and
                Xiaodan Song and
                James Demmel and
                Cho{-}Jui Hsieh},
  title      = {Reducing {BERT} Pre-Training Time from 3 Days to 76 Minutes},
  journal    = {CoRR},
  volume     = {abs/1904.00962},
  year       = {2019},
  url        = {http://arxiv.org/abs/1904.00962},
  eprinttype = {arXiv},
  eprint     = {1904.00962},
  timestamp  = {Wed, 24 Apr 2019 12:21:25 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/abs-1904-00962.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@article{10.1214/aoms/1177729392,
  author    = {J. Kiefer and J. Wolfowitz},
  title     = {{Stochastic Estimation of the Maximum of a Regression Function}},
  volume    = {23},
  journal   = {The Annals of Mathematical Statistics},
  number    = {3},
  publisher = {Institute of Mathematical Statistics},
  pages     = {462 -- 466},
  year      = {1952},
  doi       = {10.1214/aoms/1177729392},
  url       = {https://doi.org/10.1214/aoms/1177729392}
}

@misc{10.48550/arxiv.1412.6980,
  doi       = {10.48550/ARXIV.1412.6980},
  url       = {https://arxiv.org/abs/1412.6980},
  author    = {Kingma, Diederik P. and Ba, Jimmy},
  keywords  = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {Adam: A Method for Stochastic Optimization},
  publisher = {arXiv},
  year      = {2014},
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@article{DBLP:journals/corr/abs-1811-03600,
  author     = {Christopher J. Shallue and
                Jaehoon Lee and
                Joseph M. Antognini and
                Jascha Sohl{-}Dickstein and
                Roy Frostig and
                George E. Dahl},
  title      = {Measuring the Effects of Data Parallelism on Neural Network Training},
  journal    = {CoRR},
  volume     = {abs/1811.03600},
  year       = {2018},
  url        = {http://arxiv.org/abs/1811.03600},
  eprinttype = {arXiv},
  eprint     = {1811.03600},
  timestamp  = {Tue, 18 Jan 2022 08:22:59 +0100},
  biburl     = {https://dblp.org/rec/journals/corr/abs-1811-03600.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@article{10.48550/arxiv.1705.08741,
  doi       = {10.48550/ARXIV.1705.08741},
  url       = {https://arxiv.org/abs/1705.08741},
  author    = {Hoffer, Elad and Hubara, Itay and Soudry, Daniel},
  keywords  = {Machine Learning (stat.ML), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {Train longer, generalize better: closing the generalization gap in large batch training of neural networks},
  publisher = {arXiv},
  year      = {2017},
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@article{DBLP:journals/corr/abs-2106-10207,
  author     = {Michael Diskin and
                Alexey Bukhtiyarov and
                Max Ryabinin and
                Lucile Saulnier and
                Quentin Lhoest and
                Anton Sinitsin and
                Dmitry Popov and
                Dmitry V. Pyrkin and
                Maxim Kashirin and
                Alexander Borzunov and
                Albert Villanova del Moral and
                Denis Mazur and
                Ilia Kobelev and
                Yacine Jernite and
                Thomas Wolf and
                Gennady Pekhimenko},
  title      = {Distributed Deep Learning in Open Collaborations},
  journal    = {CoRR},
  volume     = {abs/2106.10207},
  year       = {2021},
  url        = {https://arxiv.org/abs/2106.10207},
  eprinttype = {arXiv},
  eprint     = {2106.10207},
  timestamp  = {Tue, 19 Apr 2022 17:04:27 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/abs-2106-10207.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-2103-03239,
  author     = {Max Ryabinin and
                Eduard Gorbunov and
                Vsevolod Plokhotnyuk and
                Gennady Pekhimenko},
  title      = {Moshpit {SGD:} Communication-Efficient Decentralized Training on Heterogeneous
                Unreliable Devices},
  journal    = {CoRR},
  volume     = {abs/2103.03239},
  year       = {2021},
  url        = {https://arxiv.org/abs/2103.03239},
  eprinttype = {arXiv},
  eprint     = {2103.03239},
  timestamp  = {Mon, 15 Mar 2021 17:30:55 +0100},
  biburl     = {https://dblp.org/rec/journals/corr/abs-2103-03239.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{10.1109/IPDPS.2009.5160922,
  author    = {Beberg, Adam L. and Ensign, Daniel L. and Jayachandran, Guha and Khaliq, Siraj and Pande, Vijay S.},
  title     = {Folding@home: Lessons from Eight Years of Volunteer Distributed Computing},
  year      = {2009},
  isbn      = {9781424437511},
  publisher = {IEEE Computer Society},
  address   = {USA},
  url       = {https://doi.org/10.1109/IPDPS.2009.5160922},
  doi       = {10.1109/IPDPS.2009.5160922},
  booktitle = {Proceedings of the 2009 IEEE International Symposium on Parallel and Distributed Processing},
  pages     = {1–8},
  numpages  = {8},
  series    = {IPDPS '09}
}

@inproceedings{10.5555/2685048.2685095,
  author    = {Li, Mu and Andersen, David G. and Park, Jun Woo and Smola, Alexander J. and Ahmed, Amr and Josifovski, Vanja and Long, James and Shekita, Eugene J. and Su, Bor-Yiing},
  title     = {Scaling Distributed Machine Learning with the Parameter Server},
  year      = {2014},
  isbn      = {9781931971164},
  publisher = {USENIX Association},
  address   = {USA},
  booktitle = {Proceedings of the 11th USENIX Conference on Operating Systems Design and Implementation},
  pages     = {583–598},
  numpages  = {16},
  location  = {Broomfield, CO},
  series    = {OSDI'14}
}

@inproceedings{NIPS20141ff1de77,
  author    = {Li, Mu and Andersen, David G and Smola, Alexander J and Yu, Kai},
  booktitle = {Advances in Neural Information Processing Systems},
  editor    = {Z. Ghahramani and M. Welling and C. Cortes and N. Lawrence and K.Q. Weinberger},
  pages     = {},
  publisher = {Curran Associates, Inc.},
  title     = {Communication Efficient Distributed Machine Learning with the Parameter Server},
  url       = {https://proceedings.neurips.cc/paper/2014/file/1ff1de774005f8da13f42943881c655f-Paper.pdf},
  volume    = {27},
  year      = {2014}
}

@article{DBLP:journals/corr/abs-1907-09693,
  author     = {Qinbin Li and
                Zeyi Wen and
                Zhaomin Wu and
                Sixu Hu and
                Naibo Wang and
                Xu Liu and
                Bingsheng He},
  title      = {A Survey on Federated Learning Systems: Vision, Hype and Reality for
                Data Privacy and Protection},
  journal    = {CoRR},
  volume     = {abs/1907.09693},
  year       = {2019},
  url        = {http://arxiv.org/abs/1907.09693},
  eprinttype = {arXiv},
  eprint     = {1907.09693},
  timestamp  = {Tue, 02 Nov 2021 07:45:37 +0100},
  biburl     = {https://dblp.org/rec/journals/corr/abs-1907-09693.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@article{9356607,
  author  = {Xian, Lintao and Li, Bingzhe and Liu, Jing and Guo, Zhongwen and Du, David H. C.},
  journal = {IEEE Access},
  title   = {H-PS: A Heterogeneous-Aware Parameter Server With Distributed Neural Network Training},
  year    = {2021},
  volume  = {9},
  number  = {},
  pages   = {44049-44058},
  doi     = {10.1109/ACCESS.2021.3060154}
}

@article{DBLP:journals/corr/abs-1708-07747,
  author     = {Han Xiao and
                Kashif Rasul and
                Roland Vollgraf},
  title      = {Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning
                Algorithms},
  journal    = {CoRR},
  volume     = {abs/1708.07747},
  year       = {2017},
  url        = {http://arxiv.org/abs/1708.07747},
  eprinttype = {arXiv},
  eprint     = {1708.07747},
  timestamp  = {Mon, 13 Aug 2018 16:47:27 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/abs-1708-07747.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{10.1145/3448016.3457566,
  author    = {Xin, Doris and Miao, Hui and Parameswaran, Aditya and Polyzotis, Neoklis},
  title     = {Production Machine Learning Pipelines: Empirical Analysis and Optimization Opportunities},
  year      = {2021},
  isbn      = {9781450383431},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3448016.3457566},
  doi       = {10.1145/3448016.3457566},
  booktitle = {Proceedings of the 2021 International Conference on Management of Data},
  pages     = {2639–2652},
  numpages  = {14},
  keywords  = {data management, machine learning pipelines},
  location  = {Virtual Event, China},
  series    = {SIGMOD '21}
}

@misc{10.48550/arxiv.2003.03033,
  doi       = {10.48550/ARXIV.2003.03033},
  url       = {https://arxiv.org/abs/2003.03033},
  author    = {Blalock, Davis and Ortiz, Jose Javier Gonzalez and Frankle, Jonathan and Guttag, John},
  keywords  = {Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {What is the State of Neural Network Pruning?},
  publisher = {arXiv},
  year      = {2020},
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@misc{10.48550/arxiv.1510.00149,
  doi       = {10.48550/ARXIV.1510.00149},
  url       = {https://arxiv.org/abs/1510.00149},
  author    = {Han, Song and Mao, Huizi and Dally, William J.},
  keywords  = {Computer Vision and Pattern Recognition (cs.CV), Neural and Evolutionary Computing (cs.NE), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding},
  publisher = {arXiv},
  year      = {2015},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{10.5555/2999134.2999271,
  author    = {Dean, Jeffrey and Corrado, Greg S. and Monga, Rajat and Chen, Kai and Devin, Matthieu and Le, Quoc V. and Mao, Mark Z. and Ranzato, Marc'Aurelio and Senior, Andrew and Tucker, Paul and Yang, Ke and Ng, Andrew Y.},
  title     = {Large Scale Distributed Deep Networks},
  year      = {2012},
  publisher = {Curran Associates Inc.},
  address   = {Red Hook, NY, USA},
  abstract  = {Recent work in unsupervised feature learning and deep learning has shown that being able to train large models can dramatically improve performance. In this paper, we consider the problem of training a deep network with billions of parameters using tens of thousands of CPU cores. We have developed a software framework called DistBelief that can utilize computing clusters with thousands of machines to train large models. Within this framework, we have developed two algorithms for large-scale distributed training: (i) Downpour SGD, an asynchronous stochastic gradient descent procedure supporting a large number of model replicas, and (ii) Sandblaster, a framework that supports a variety of distributed batch optimization procedures, including a distributed implementation of L-BFGS. Downpour SGD and Sandblaster L-BFGS both increase the scale and speed of deep network training. We have successfully used our system to train a deep network 30x larger than previously reported in the literature, and achieves state-of-the-art performance on ImageNet, a visual object recognition task with 16 million images and 21k categories. We show that these same techniques dramatically accelerate the training of a more modestly- sized deep network for a commercial speech recognition service. Although we focus on and report performance of these methods as applied to training large neural networks, the underlying algorithms are applicable to any gradient-based machine learning algorithm.},
  booktitle = {Proceedings of the 25th International Conference on Neural Information Processing Systems - Volume 1},
  pages     = {1223–1231},
  numpages  = {9},
  location  = {Lake Tahoe, Nevada},
  series    = {NIPS'12}
}

@inproceedings{Atre_2021,
  doi       = {10.1109/ipdpsw52791.2021.00144},
  url       = {https://doi.org/10.1109%2Fipdpsw52791.2021.00144},
  year      = 2021,
  month     = {jun},
  publisher = {{IEEE}},
  author    = {Medha Atre and Birendra Jha and Ashwini Rao},
  title     = {Distributed Deep Learning Using Volunteer Computing-Like Paradigm},
  booktitle = {2021 {IEEE} International Parallel and Distributed Processing Symposium Workshops ({IPDPSW})}
}

@article{8886576,
  author  = {Morell, José Á. and Camero, Andrés and Alba, Enrique},
  journal = {IEEE Access},
  title   = {JSDoop and TensorFlow.js: Volunteer Distributed Web Browser-Based Neural Network Training},
  year    = {2019},
  volume  = {7},
  number  = {},
  pages   = {158671-158684},
  doi     = {10.1109/ACCESS.2019.2950287}
}

@misc{leclerc2022ffcv,
  author       = {Guillaume Leclerc and Andrew Ilyas and Logan Engstrom and Sung Min Park and Hadi Salman and Aleksander Madry},
  title        = {ffcv},
  year         = {2022},
  howpublished = {\url{https://github.com/libffcv/ffcv/}},
  note         = {commit xxxxxxx}
}

@article{DBLP:journals/corr/abs-2006-09882,
  author     = {Mathilde Caron and
                Ishan Misra and
                Julien Mairal and
                Priya Goyal and
                Piotr Bojanowski and
                Armand Joulin},
  title      = {Unsupervised Learning of Visual Features by Contrasting Cluster Assignments},
  journal    = {CoRR},
  volume     = {abs/2006.09882},
  year       = {2020},
  url        = {https://arxiv.org/abs/2006.09882},
  eprinttype = {arXiv},
  eprint     = {2006.09882},
  timestamp  = {Tue, 23 Jun 2020 17:57:22 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/abs-2006-09882.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-2106-11257,
  author     = {Eduard Gorbunov and
                Alexander Borzunov and
                Michael Diskin and
                Max Ryabinin},
  title      = {Secure Distributed Training at Scale},
  journal    = {CoRR},
  volume     = {abs/2106.11257},
  year       = {2021},
  url        = {https://arxiv.org/abs/2106.11257},
  eprinttype = {arXiv},
  eprint     = {2106.11257},
  timestamp  = {Thu, 14 Oct 2021 09:16:21 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/abs-2106-11257.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-2006-10103,
  author     = {Zhen Zhang and
                Chaokun Chang and
                Haibin Lin and
                Yida Wang and
                Raman Arora and
                Xin Jin},
  title      = {Is Network the Bottleneck of Distributed Training?},
  journal    = {CoRR},
  volume     = {abs/2006.10103},
  year       = {2020},
  url        = {https://arxiv.org/abs/2006.10103},
  eprinttype = {arXiv},
  eprint     = {2006.10103},
  timestamp  = {Fri, 29 Jan 2021 16:26:31 +0100},
  biburl     = {https://dblp.org/rec/journals/corr/abs-2006-10103.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@misc{10.48550/arxiv.1409.1556,
  doi       = {10.48550/ARXIV.1409.1556},
  url       = {https://arxiv.org/abs/1409.1556},
  author    = {Simonyan, Karen and Zisserman, Andrew},
  keywords  = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {Very Deep Convolutional Networks for Large-Scale Image Recognition},
  publisher = {arXiv},
  year      = {2014},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{leclerc2022ffcv,
  author       = {Guillaume Leclerc and Andrew Ilyas and Logan Engstrom and Sung Min Park and Hadi Salman and Aleksander Madry},
  title        = {ffcv},
  year         = {2022},
  howpublished = {\url{https://github.com/libffcv/ffcv/}},
  note         = {commit xxxxxxx}
}
